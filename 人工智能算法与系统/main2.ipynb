{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83da8da4",
   "metadata": {},
   "source": [
    "# 金融异常检测任务"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e125c73d",
   "metadata": {},
   "source": [
    "## 1. 实验介绍\n",
    "\n",
    "反欺诈是金融行业永恒的主题，在互联网金融信贷业务中，数字金融反欺诈技术已经得到广泛应用并取得良好效果，这其中包括了近几年迅速发展并在各个领域\n",
    "得到越来越广泛应用的神经网络。本项目以互联网智能风控为背景，从用户相互关联和影响的视角，探索满足风控反欺诈领域需求的，可拓展、高效的神经\n",
    "网络应用方案，从而帮助更好地识别欺诈用户。\n",
    "\n",
    "本项目主要关于实现预测模型(**项目用图神经网络举例，具体实现可以使用其他模型**)，进行节点异常检测任务，并验证模型精度。而本项目基于的数据集[DGraph](https://dgraph.xinye.com/introduction)，[DGraph](https://dgraph.xinye.com/introduction)\n",
    "是大规模动态图数据集的集合，由真实金融场景中随着时间演变事件和标签构成。\n",
    "\n",
    "### 1.1 实验目的\n",
    "\n",
    "- 了解如何使用Pytorch进行神经网络训练\n",
    "- 了解如何使用Pytorch-geometric等图网络深度学习库进行简单图神经网络设计(推荐使用GAT, GraphSAGE模型)。\n",
    "- 了解如何利用MO平台进行模型性能评估。\n",
    "\n",
    "### 1.2 预备知识\n",
    "- 具备一定的深度学习理论知识，如卷积神经网络、损失函数、优化器，训练策略等。\n",
    "- 了解并熟悉Pytorch计算框架。\n",
    "- 学习Pytorch-geometric，请前往：https://pytorch-geometric.readthedocs.io/en/latest/\n",
    "    \n",
    "### 1.3实验环境\n",
    "- numpy = 1.26.4  \n",
    "- pytorch = 2.3.1  \n",
    "- torch_geometric = 2.5.3  \n",
    "- torch_scatter = 2.1.2  \n",
    "- torch_sparse = 0.6.18  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a9ac89",
   "metadata": {},
   "source": [
    "## 2. 实验内容"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bd80be",
   "metadata": {},
   "source": [
    "### 2.1 数据集信息\n",
    "DGraph-Fin 是一个由数百万个节点和边组成的有向无边权的动态图。它代表了Finvolution Group用户之间的社交网络，其中一个节点对应一个Finvolution 用户，从一个用户到另一个用户的边表示**该用户将另一个用户视为紧急联系人**。\n",
    "下面是`位于dataset/DGraphFin目录`的DGraphFin数据集的描述:\n",
    "```\n",
    "x:  20维节点特征向量\n",
    "y:  节点对应标签，一共包含四类。其中类1代表欺诈用户而类0代表正常用户(实验中需要进行预测的两类标签)，类2和类3则是背景用户，即无需预测其标签。\n",
    "edge_index:  图数据边集,每条边的形式(id_a,id_b)，其中ids是x中的索引\n",
    "edge_type: 共11种类型的边\n",
    "edge_timestamp: 脱敏后的时间戳\n",
    "train_mask, valid_mask, test_mask: 训练集，验证集和测试集掩码\n",
    "```\n",
    "本预测任务为识别欺诈用户的节点预测任务,只需要将欺诈用户（Class 1）从正常用户（Class 0）中区分出来。需要注意的是，其中测试集中样本对应的label**均被标记为-100**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e8abb2",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### 2.2 导入相关包\n",
    "\n",
    "导入相应模块，设置数据集路径、设备等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846ae6f1",
   "metadata": {},
   "source": [
    "### 2.3 数据处理\n",
    "\n",
    "在使用数据集训练网络前，首先需要对数据进行归一化等预处理，如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752047e7",
   "metadata": {},
   "source": [
    "这里我们可以查看数据各部分维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "942cc69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "from torch import Tensor\n",
    "from torch_sparse import SparseTensor\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self\n",
    "                 , in_channels\n",
    "                 , hidden_channels\n",
    "                 , out_channels\n",
    "                 , num_layers\n",
    "                 , dropout\n",
    "                 , batchnorm=True):\n",
    "        super(SAGE, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.batchnorm = batchnorm\n",
    "        if self.batchnorm:\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "            if self.batchnorm:\n",
    "                self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        if self.batchnorm:\n",
    "            for bn in self.bns:\n",
    "                bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index: Union[Tensor, SparseTensor]):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, edge_index)\n",
    "            if self.batchnorm:\n",
    "                x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        return x.log_softmax(dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3939c025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from utils import DGraphFin\n",
    "import torch_geometric.transforms as T\n",
    "from utils.evaluator import Evaluator\n",
    "\n",
    "path = './datasets/632d74d4e2843a53167ee9a1-momodel/'\n",
    "save_dir = './results/'  # 模型保存路径\n",
    "dataset_name = 'DGraph'\n",
    "dataset = DGraphFin(root=path, name=dataset_name, transform=T.ToSparseTensor())\n",
    "\n",
    "nlabels = dataset.num_classes\n",
    "if dataset_name in ['DGraph']:\n",
    "    nlabels = 2  # 本实验中仅需预测类0和类1\n",
    "data = dataset[0]\n",
    "data.adj_t = data.adj_t.to_symmetric()  # 将有向图转化为无向图\n",
    "\n",
    "\n",
    "if dataset_name in ['DGraph']:\n",
    "    x = data.x\n",
    "    x = (x - x.mean(0)) / x.std(0)\n",
    "    data.x = x\n",
    "if data.y.dim() == 2:\n",
    "    data.y = data.y.squeeze(1)\n",
    "\n",
    "split_idx = {'train': data.train_mask, 'valid': data.valid_mask, 'test': data.test_mask}  # 划分训练集，验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "996347fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric = 'auc'\n",
    "evaluator = Evaluator(eval_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab475b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, train_idx, optimizer):\n",
    "    # data.y is labels of shape (N, )\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    out = model(data.x, data.adj_t)[train_idx]\n",
    "\n",
    "    loss = F.nll_loss(out, data.y[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d96e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(model, data, split_idx, evaluator):\n",
    "    # data.y is labels of shape (N, )\n",
    "    model.eval()\n",
    "\n",
    "    out = model(data.x, data.adj_t)\n",
    "\n",
    "    y_pred = out.exp()  # (N,num_classes)\n",
    "\n",
    "    losses, eval_results = dict(), dict()\n",
    "    for key in ['train', 'valid']:\n",
    "        node_id = split_idx[key]\n",
    "        losses[key] = F.nll_loss(out[node_id], data.y[node_id]).item()\n",
    "        eval_results[key] = evaluator.eval(data.y[node_id], y_pred[node_id])[eval_metric]\n",
    "\n",
    "    return eval_results, losses, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0630258",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'logger'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prepare_folder\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlogger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Logger\n\u001b[1;32m     11\u001b[0m args \u001b[38;5;241m=\u001b[39m argparse\u001b[38;5;241m.\u001b[39mNamespace(\n\u001b[1;32m     12\u001b[0m     log_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     13\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m     14\u001b[0m     runs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'logger'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch_geometric.transforms as T\n",
    "from utils import DGraphFin\n",
    "from utils.utils import prepare_folder\n",
    "import numpy as np\n",
    "\n",
    "args = argparse.Namespace(\n",
    "    log_steps=10,\n",
    "    epochs=200,\n",
    "    runs=10,\n",
    ")\n",
    "\n",
    "device = torch.device(f'cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "723490b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAGE(\n",
    "    in_channels=data.x.size(-1),\n",
    "    out_channels=nlabels,\n",
    "    **{\n",
    "        'num_layers': 2,\n",
    "        'hidden_channels': 128,\n",
    "        'dropout': 0,\n",
    "        'batchnorm': False\n",
    "    }).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a98c48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5762\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "print(sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30002b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reset_parameters()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-7)\n",
    "best_valid = 0\n",
    "min_valid_loss = 1e8\n",
    "best_out = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b216fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.virtualenvs/basenv/lib/python3.9/site-packages/torch_sparse/tensor.py:574: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  return torch.sparse_csr_tensor(rowptr, col, value, self.sizes())\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 300):\n",
    "    loss = train(model, data, split_idx['train'], optimizer)\n",
    "    eval_results, losses, out = test(model, data, split_idx, evaluator)\n",
    "    train_eval, valid_eval = eval_results['train'], eval_results['valid']\n",
    "    train_loss, valid_loss = losses['train'], losses['valid']\n",
    "\n",
    "    if valid_loss < min_valid_loss:\n",
    "        min_valid_loss = valid_loss\n",
    "        best_out = out.cpu()\n",
    "        torch.save(model.state_dict(), save_dir+'/model.pt')\n",
    "\n",
    "    if epoch % args.log_steps == 0:\n",
    "        print(f'Epoch: {epoch:02d}, '\n",
    "              f'Loss: {loss:.4f}, '\n",
    "              f'Train: {100 * train_eval:.3f}%, '\n",
    "              f'Valid: {100 * valid_eval:.3f}% ')\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    res = model(data.x, data.adj_t)\n",
    "    res = res.exp()\n",
    "    \n",
    "res.cpu().numpy().tofile('res.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3c3059",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "### 2.6 模型预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d5e163",
   "metadata": {},
   "source": [
    "## 3. 作业评分\n",
    "\n",
    "**作业要求**：    \n",
    "                         \n",
    "1. 请加载你认为训练最佳的模型（不限于图神经网络)\n",
    "2. 提交的作业包括【程序报告.pdf】和代码文件。\n",
    "\n",
    "**注意：**\n",
    "          \n",
    "1. 在训练模型等过程中如果需要**保存数据、模型**等请写到 **results** 文件夹，如果采用 [离线任务](https://momodel.cn/docs/#/zh-cn/%E5%9C%A8GPU%E6%88%96CPU%E8%B5%84%E6%BA%90%E4%B8%8A%E8%AE%AD%E7%BB%83%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B) 请务必将模型保存在 **results** 文件夹下。\n",
    "2. 训练出自己最好的模型后，先按照下列 cell 操作方式实现 NoteBook 加载模型测试；请测试通过在进行【系统测试】。\n",
    "3. 点击左侧栏`提交作业`后点击`生成文件`则只需勾选 `predict()` 函数的cell，即【**模型预测代码答题区域**】的 cell。\n",
    "4. 请导入必要的包和第三方库 (包括此文件中曾经导入过的)。\n",
    "5. 请加载你认为训练最佳的模型，即请按要求填写**模型路径**。\n",
    "6. `predict()`函数的输入和输出请不要改动。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6602e84",
   "metadata": {},
   "source": [
    "===========================================  **模型预测代码答题区域**  =========================================== \n",
    "\n",
    "在下方的代码块中编写 **模型预测** 部分的代码，请勿在别的位置作答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e013914",
   "metadata": {
    "select": true
   },
   "outputs": [],
   "source": [
    "## 生成 main.py 时请勾选此 cell\n",
    "from utils import DGraphFin\n",
    "from utils.evaluator import Evaluator\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# path = './datasets/632d74d4e2843a53167ee9a1-momodel/'\n",
    "# save_dir = './results/'  # 模型保存路径\n",
    "# dataset_name = 'DGraph'\n",
    "# dataset = DGraphFin(root=path, name=dataset_name, transform=T.ToSparseTensor())\n",
    "\n",
    "# nlabels = dataset.num_classes\n",
    "# if dataset_name in ['DGraph']:\n",
    "#     nlabels = 2  # 本实验中仅需预测类0和类1\n",
    "# data = dataset[0]\n",
    "# data.adj_t = data.adj_t.to_symmetric() \n",
    "\n",
    "# # 确定设备：如果有 GPU 则使用 GPU，否则使用 CPU\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# # 加载数据并将其移动到设备上\n",
    "# data = data.to(device)\n",
    "\n",
    "# # 定义模型\n",
    "# model = SAGE(\n",
    "#     in_channels=data.x.size(-1),\n",
    "#     out_channels=nlabels,\n",
    "#     **{\n",
    "#         'num_layers': 2,\n",
    "#         'hidden_channels': 128,\n",
    "#         'dropout': 0,\n",
    "#         'batchnorm': False\n",
    "#     }).to(device)\n",
    "\n",
    "# # 加载模型权重时，处理 CPU 和 GPU 的情况\n",
    "# if device.type == 'cpu':\n",
    "#     # 如果当前设备是 CPU，则将模型映射到 CPU\n",
    "#     model.load_state_dict(torch.load('./results/model.pt', map_location=torch.device('cpu')))\n",
    "# else:\n",
    "#     # 如果当前设备是 GPU，则直接加载到 GPU\n",
    "#     model.load_state_dict(torch.load('./results/model.pt'))\n",
    "    \n",
    "res = np.fromfile('./results/res.pkl', dtype=np.float32).reshape(-1, 2)\n",
    "\n",
    "\n",
    "\n",
    "def predict(data,node_id):\n",
    "    \"\"\"\n",
    "    加载模型和模型预测\n",
    "    :param node_id: int, 需要进行预测节点的下标\n",
    "    :return: tensor, 类0以及类1的概率, torch.size[1,2]\n",
    "    \"\"\"\n",
    "\n",
    "    # 模型预测时，测试数据已经进行了归一化处理\n",
    "\n",
    "\n",
    "    return res[node_id]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
